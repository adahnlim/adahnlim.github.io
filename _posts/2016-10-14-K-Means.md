--- 
layout: post
title:  Spark - K-Means Clustering
description: Spark MLlib(K-Means)를 통한 데이터 클러스터링
tags: spark scala k-means clustering data-science Mastering-Apache-Spark mllib
--- 

PACKT사의 'Mastering Apache Spark'에서 사용되는 예제들을 중심으로 학습하였다.

학습에 사용된 데이터 또한 책에서 소개한 데이터 [영국정부공공데이터](https://data.gov.uk/dataset/road-accidents-safety-data/resource/a7583887-cbc2-4bb7-be1f-17b3bb5e0e11) 를 이용하였다.

- K-Means Algorithm
    
    [Wikipia](https://ko.wikipedia.org/wiki/K-평균_알고리즘)에 나와있는 것 처럼 주어진 데이터를 k개의 클러스터로 묶는 알고리즘으로, 각 클러스터와 거리 차이의 분산을 최소화 하는 방식으로 동작한다.

- Source

    [Github 참고](https://github.com/adahnlim/Mastering_Apache_Spark_Exam/blob/master/kmenas/src/main/scala/kmeans.scala)

- Result
    
        Input Dat rows : 497790
        K Means Cost : 5.63910...
        [0.2318,...]
        [0.159.....]
        [0.2084....]
        (0,438621)
        (1,48267)
        (2,10902)

- Summary

    K-Means알고리즘은 입력되는 k에 따라 클러스터링 구조가 바뀌기 때문에 데이터에 적합한 k를 선정하는 것이 중요하다. 
    예제에서 k를 증가시키면 k Means Cost는 적어지지만, 원하지 않게 그룹핑이 될 수 있음을 유의해야 한다.


    
